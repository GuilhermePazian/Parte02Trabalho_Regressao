---
title: ""
geometry: textwidth=18cm,textheight=21cm
setspace: doublespacing
lang: pt-br
header-includes:
- \usepackage{setspace}
- \usepackage{indentfirst}
- \usepackage[utf8]{inputenc}
- \usepackage{mathptmx}
- \usepackage{enumerate}
- \usepackage{url} 
- \usepackage{lipsum}
output:
  pdf_document:
  html_document: default
  fig_caption: yes
  mainfont: Times New Roman
  
fontsize: 10pt
---

\begin{titlepage}
\begin{center}
\thispagestyle{empty}
\begin{figure}[!htb]
\begin{center}
\begin{minipage}[b]{0.5\linewidth}
\begin{center}
\includegraphics[width=100pt,height=150pt]{logo/logoimeccunicamp.png}
\end{center}
\end{minipage}
\begin{minipage}[b]{0.7\linewidth}
\begin{center}
\vspace*{1cm}
 {\large \bf Universidade Estadual de Campinas\\[5pt]
Instituto de Matemática, Estatística e Computação Cientifica\\[3pt]
Departamento de Estatística}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\vspace*{\stretch{1}}
\begin{center}
\vspace*{5cm}
{\huge \bf Relatório - Parte II \\[7pt]
Trabalho Final de ME613}
\end{center}
\vspace*{\stretch{1}}
\begin{center}
\vspace*{4cm}
{\Large \bf Eliane Ramos de Siqueira  RA:155233 \\
Guilherme Pazian  RA:160323 \\
Henrique Capatto  RA:146406 \\
Murilo Salgado Razoli  RA:150987 \break
}\\[3pt]
{\large \bf Professor: Caio Lucidius Naberezny Azevedo}\\[5pt]
\end{center}
\vspace*{\stretch{1}}
\centerline{\bf Campinas-SP, 08 de Dezembro de 2016}
\vspace*{\stretch{1}}
\end{center}
\end{titlepage}

\onehalfspacing
\newpage

```{r pacotes,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE, error = FALSE}
#eval= FALSE faz com que o R ignore este chunk
#echo = FALSE não permite que o chunk apareça no pdf

#pacotes = c("tidyverse","plyr","dplyr","reshape2","knitr")
#install.packages(pacotes)

# pacote utiliado para gráficos
library(ggplot2)
# pacote que deixa os gráficos do ggplot lado a lado
library(gridExtra)
# pacotes para manipulação de dados
library(reshape2)
library(plyr)
library(dplyr)
#pacote que possui o conjunto de dados para o primeiro exercício
library(car)
#pacote para fazer legenda
library(captioner)



figs <- captioner(prefix="Figura")
tbls <- captioner(prefix="Tabela")

#inslação dos pacotes necessários
#install.packages(c("tidyverse","gridExtra","car","captioner","gvlma"))

#instalacao de um pacote pra "printar" tabelas mais bonitinhas
#install.packages(
# 'printr',
# type = 'source',
# repos = c('http://yihui.name/xran', 'http://cran.rstudio.com')
#)

```

```{r legendas, cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#legenda para as tabelas

# legenda para a primeira tabela(estats descr) do primeiro exercício
legenda_table1 = tbls(name="table_estat_descr1",caption = "Estatísticas Descritivas")
legenda_table2 = tbls(name="table_comparacao",caption = "Estimativas dos parâmetros, intervalo de confiança e teste de nulidade para o modelo 1")
legenda_table3 = tbls(name="table_comparacao",caption = "Tabela de comparação")
legenda_table4 = tbls(name="table_mult",caption = "Tabela dos coeficientes de correlação linear entre as covariáveis")
legenda_table5 = tbls(name="table_comp",caption = "Tabela de Comparação")

#legendas para os gráficos

#legenda para o primeiro Boxplot
legenda_graf1 = figs(name="graf1_dispersao",caption = "Gráficos de dispersão")
#legenda para o primeiro grárico de dispersão
legenda_graf2 = figs(name="graf2_residuos",caption = "Análise de Resíduo para o modelo 1")
legenda_graf3 = figs(name="graf3_residuos",caption = "Gráfico de envelope para o resíduos studentizado para o modelo 1")
legenda_graf4 = figs(name="graf4_residuos",caption = "Análise residual para o modelo 2")
legenda_graf5 = figs(name="graf5_envelope",caption = "Gráfico de envelope para o resíduos studentizado para o modelo 2")
legenda_graf6 = figs(name="graf6_analiseresidual",caption = "Análise residual para o modelo 3")
legenda_graf7 = figs(name="graf7_envelope",caption = "Gráfico de envelope para o resíduos studentizado para o modelo 3")
legenda_graf8 = figs(name="graf8_analiseresidual",caption = "ESCOLHER LEGENDA")
legenda_graf9 = figs(name="graf9_residuo",caption = "Gráfico de resíduos para o modelo 4 CONFERIR")
legenda_graf10 = figs(name="graf10_envelope",caption = "Gráfico de envelope para o resíduos studentizado para OQUE? ")
legenda_graf11 = figs(name="graf11_residuo",caption = "Gráfico de resíduos para Oque?")
legenda_graf12 = figs(name="graf12_residuo",caption = "Gráfico de envelopes para ... ")
```




```{r Funcoes,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

library(ggplot2)
library(gridExtra)
# Programa extraído do site: https://www.ime.usp.br/~giapaula/textoregressao.htm
# Créditos: Prof. Dr. Gilberto Alvarenga Paula
# Adaptado por Caio L. N. Azevedo
# source("C:\\Users\\cnaber\\Trabalho\\windows\\Unicamp\\Disciplinas\\2_semestre_2016\\ME 613\\Programas\\diag2_norm.r")


diag2norm<-function(fit.model){
# fit.model: objeto com o ajuste do modelo normal linear homocedástico 
# obtido através da função "lm"

  
  
X <- model.matrix(fit.model)
n <- nrow(X)
p <- ncol(X)
H <- X%*%solve(t(X)%*%X)%*%t(X)
h <- diag(H)
lms <- summary(fit.model)
s <- lms$sigma
r <- resid(lms)
ts <- r/(s*sqrt(1-h))
di <- (1/p)*(h/(1-h))*(ts^2)
si <- lm.influence(fit.model)$sigma
tsi <- r/(si*sqrt(1-h))
tam <- 1:length(tsi)
a <- max(tsi)
b <- min(tsi)

g1 = ggplot(data=data.frame(tam,tsi),aes(tam,tsi))+ geom_point() +scale_y_continuous(name = "Resíduo Studentizado",limits=c(b-1,a+1)) +scale_x_continuous(name = "Índice")+labs(title="A")+geom_hline(yintercept=0,size=0.25,linetype=2)+geom_hline(yintercept=2,size=0.25,linetype=2)+geom_hline(yintercept=-2,size=0.25,linetype=2)+theme_light()

g2 =  ggplot(data=data.frame(fitted(fit.model),tsi),aes(fitted(fit.model),tsi))+ geom_point() +scale_y_continuous(name = "Resíduo Studentizado",limits=c(b-1,a+1)) +scale_x_continuous(name = "Valores Ajustados")+labs(title="B")+geom_hline(yintercept=0,size=0.25,linetype=2)+geom_hline(yintercept=2,size=0.25,linetype=2)+geom_hline(yintercept=-2,size=0.25,linetype=2)+theme_light()

#Histograma
g3 = ggplot(data=data.frame(tsi),aes(tsi,col=I("black"),fill=I("white")))+geom_histogram(binwidth = 1,aes(y=..density..))+labs(title="C",x="Resíduo Studentizado",y="Densidade")+theme_light()

#Boxplot
g4 = ggplot(data=data.frame(fac = factor(1),tsi),aes(fac,tsi,col=I("black"),fill=I("white")))+ geom_boxplot(outlier.size = 1.5, outlier.colour = "red",width=0.4)+labs(title="D")+scale_x_discrete(name="")+scale_y_continuous(name = "Residuo Studentizado")+theme(axis.text.x = element_blank())+theme_light()

#funcao que une todos os gráficos
grid.arrange(g1,g2,g3,g4,ncol=2,nrow=2)
#---------------------------------------------------------------#

}

# Programa extraído do site: https://www.ime.usp.br/~giapaula/textoregressao.htm
# Créditos: Prof. Dr. Gilberto Alvarenga Paula
# Adaptado por Caio L. N. Azevedo e Henrique Capatto

envelnorm<-function(fit.model){  
# argumento: modelo de regressão linear homocedástico ajustado
# Eu adaptei uma função que achei na net com o que o Caio fez nos grafs de envelope. Agradeçam a um desconhecido.  

  
  
    X <- model.matrix(fit.model)
    n <- nrow(X)
    p <- ncol(X)
    H <- X%*%solve(t(X)%*%X)%*%t(X)
    h <- diag(H)
    si <- lm.influence(fit.model)$sigma
    r <- resid(fit.model)
    tsi <- r/(si*sqrt(1-h))
    #
    ident <- diag(n)
    epsilon <- matrix(0,n,100)
    e <- matrix(0,n,100)
    e1 <- numeric(n)
    e2 <- numeric(n)
    #
    for(i in 1:100){
        epsilon[,i] <- rnorm(n,0,1)
        e[,i] <- (ident - H)%*%epsilon[,i]
        u <- diag(ident - H)
        e[,i] <- e[,i]/sqrt(u)
        e[,i] <- sort(e[,i]) }
    #
    for(i in 1:n){
        eo <- sort(e[i,])
        e1[i] <- (eo[2]+eo[3])/2
        e2[i] <- (eo[97]+eo[98])/2 }
  
  
    y <- quantile(tsi[!is.na(tsi)], c(0.25, 0.75))
    x <- qnorm(c(0.25, 0.75))
    slope <- diff(y)/diff(x)
    int <- y[1L] - slope * x[1L]
  
    d <- data.frame(resids = tsi)
  
    ggplot(d, aes(sample = resids))+stat_qq()+stat_qq(aes(sample=e1),geom="line")+stat_qq(aes(sample=e2),geom="line")+ geom_abline(slope = slope, intercept = int,linetype = 3)+labs(x="Percentil da N(0,1)",y="Residuo Studentizado",title="E")+theme_light()
}




#função para "medidas de influência e alavancagem"




anainflu_norm<-function(fit.model){
  # fit.model: objeto com o ajuste do modelo normal linear homocedástico 
  # obtido através da função "lm"
  X <- model.matrix(fit.model)
  n <- nrow(X)
  p <- ncol(X)
  H <- X%*%solve(t(X)%*%X)%*%t(X)
  h <- diag(H)
  lms <- summary(fit.model)
  s <- lms$sigma
  r <- resid(lms)
  ts <- r/(s*sqrt(1-h))
  di <- (1/p)*(h/(1-h))*(ts^2)
  si <- lm.influence(fit.model)$sigma
  tsi <- r/(si*sqrt(1-h))
  a <- max(tsi)
  b <- min(tsi)
  ind = 1:length(h)
  cut <- 2*p/n
  
  #Gráfico Medida h
  g1 = ggplot(data=data.frame(ind=ind,h=h),aes(ind,h))+geom_point()+labs(x="Indice",y="Medida h")+geom_abline(intercept = cut, slope=0, linetype = 2)+theme_light()
  
  #Gráfico distância de Cook
  g2 = ggplot(data=data.frame(ind=ind,di=di),aes(ind,di))+geom_point()+labs(x="Indice",y="Distância de Cook")+theme_light()
  
  grid.arrange(g1,g2,ncol = 2,nrow = 1)
  #
  #------------------------------------------------------------#
}

anainflu_ind = function(fit.model){ 
# fit.model: objeto com o ajuste do modelo normal linear homocedástico 
# obtido através da função "lm"
X <- model.matrix(fit.model)
n <- nrow(X)
p <- ncol(X)
H <- X%*%solve(t(X)%*%X)%*%t(X)
h <- diag(H)
lms <- summary(fit.model)
s <- lms$sigma
r <- resid(lms)
ts <- r/(s*sqrt(1-h))
di <- (1/p)*(h/(1-h))*(ts^2)

maxh = as.integer(which.max(h))

maxdi = as.integer(which(di > 0.15))

maxs = list(maxh,as.double(h[maxh]),maxdi[1],maxdi[2],as.double(di[maxdi][1]),as.double(di[maxdi][2]))

return(maxs)
}

```

\begin{enumerate}
\item Introdução
\end{enumerate}
\vspace{0.3cm}
\setlength{\parindent}{3em}

Este presente trabalho é parte do escopo da disciplina ME613 - Regressão Linear e visa a aplicação dos conhecimentos adquiridos em sala de aula. Grande parte do trabalho foi baseado e adaptado a partir dos materiais disponibilizados na página do curso: [http://www.ime.unicamp.br/~cnaber/Material_ME613_2S_2016.htm]("http://www.ime.unicamp.br/~cnaber/Material_ME613_2S_2016.htm").  
O conjunto de dados a ser analisado está disponível em na página do curso sob o nome "reg3.dat". Neste são  descritas as seguintes variáveis referentes a 50 estados norte-americanos: (i) **estado** (nome do estado), (ii) **pop** (população estimada em julho de 1975), (iii) **percap** (renda percapita em 1974 em USD), (iv) **analf** (proporção de analfabetos em 1970), (v) **expvida** (expectativa de vida em anos 1969-70), (vi) **crime** (taxa de criminalidade por 100000 habitantes 1976), (vii) **estud** (porcentagem de estudantes que concluem o segundo grau 1970), (viii) **ndias** (número de dias do ano com temperatura abaixo de zero grau Celsus na cidade mais importante do estado) e (ix) **area** (área do estado em milhas quadradas). O objetivo do estudo é tentar explicar a variável **expvida** usando um modelo de regressão normal linear dadas as variáveis explicativas **percap**, **analf**, **crime**, **estud**, **ndias** e **dens**, em que **dens**=pop/area (densidade da população estimada em julho de 1975 por área do estado em milhas quadradas).  
Todos os modelos neste trabalho foram ajustados via metodologia de mínimos quadrados ordinários, veja Azevedo (2016), e todas suas respectivas análises residuais foram realizadas, conforme Paula (2013).
A menos que seja citado o contrário, todas as variáveis que constam na base de dados serão referidas por sua descrição completa ou pelo nome que consta no banco de dados (estes foram supracitados em negrito). Denotaremos também:
 
\noindent  
$Y_i$ - i-ésima observação da variável expvida  
$x_{1i}$ - i-esima observação da variável percap  
$x_{2i}$ - i-esima observação da variável analf  
$x_{3i}$ - i-esima observação da variável crime  
$x_{4i}$ - i-esima observação da variável estud  
$x_{5i}$ - i-esima observação da variável ndias  
$x_{6i}$ - i-esima observação da variável dens  

\vspace{0.5cm}

```{r leitura,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf
library(plyr)
library(tidyverse)
library(dplyr)

#leitura dos dados

dados = read.table("http://www.ime.unicamp.br/~cnaber/reg3.dat")
names(dados)=c("Estado","pop","percap","analf","expvida","crime","estud","ndias","area")

#criação variável dens
dados = dados %>% mutate(dens=pop/area)

#seleção das variáveis segundo orientação do Caio
dados = dados %>% select(percap, analf, crime, estud, ndias,dens,expvida)
```

\vspace{0.5cm}
\begin{enumerate}
\setcounter{enumi}{1}
\item Análise descritiva
\end{enumerate}
\vspace{0.3cm}

\begin{center}
`r legenda_table1`
\end{center}

```{r descritivas,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

library(reshape2)
library(printr)

#manipulação dos dados

estat_desc <- dados
estat_desc$Estado = NULL

df <- melt(estat_desc, id.vars = 0)

#tabela resumo

resumo <- ddply(df, c("variable"), function(x) summary(x$value))
#arredondando os valores !!! tentar arredondar os decimais porem manter os discretos com somente o valor!!!
resumo[,2:ncol(resumo)] <- round(resumo[,2:ncol(resumo)],4)
resumo
```

```{r boxplots,cache = TRUE,echo=FALSE, warning = FALSE,eval=FALSE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf
#eval= FALSE faz com que o R ignore este chunk

# !!!acho que boxplots não são nescessários neste caso, já que temos todas as variáveis contínuas (ou discretas), ou seja, nenhum fator!!!

#boxplots
ggplot(df, aes(x = variable, y =  value)) +
  geom_boxplot() +
  facet_wrap(~variable, scales = "free") +  theme_bw()
```

Dado a natureza quantitativa dos dados, é de grande interesse que identifiquemos as relações entre as covariáveis explicativas e a variável resposta, a fim de tornar essas relações visuais, foi construido graficos de dispersão entre a variável resposta e entre todas as covariáveis de interesse. Estes estão representados na figura XX. 

```{r dispersao,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#gráficos de dispersão
dispersao <- melt(estat_desc, id.vars = 7)
ggplot(dispersao, aes(x = value, y =  expvida)) +
  geom_point() +
  facet_wrap(~variable, scales = "free") +  theme_bw()
```

\begin{center}
`r legenda_graf1` 
\end{center}

A partir da Figura 1, podemos identificar visualmente a relação supracitada, a qual identificamos que todas as covariáveis parecem ter uma relação linear significativa, as quais existem relações lineares negativas entre a variável resposta e as covariáveis "analf" e "crime", assim como relações lineares negativas entre a variável resposta "expvida" e as covariáveis "percap","estud","ndias" e "dens" (a menos a um ponto).

\vspace{0.5cm}
\begin{enumerate}
\setcounter{enumi}{2}
\item Análise Inferencial
\end{enumerate}
\vspace{0.3cm}


```{r padronizacao,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf


#Padronizacao dos dados
dados[,c(1:(ncol(dados)-1))] =  sapply(dados[,c(1:(ncol(dados)-1))], function(x) (x-mean(x))/sd(x))

```

Dada a constatação visual de relações lineares entre a variável resposta "expvida" e todas as covariáveis explicativas, é razoável iniciar um modelo que contemple todas estas covariáveis. Visando poder comparar diretamente os coeficiêntes do modelo, optamos por introduzir as covariáveis com médias e variâncias iguais, tornardo-as adimensionais. Portanto, vamos iniciar a análise com o seguinte modelo:

\vspace{0.5cm}
Modelo 1:

$$
Y_i = \beta_0 + \sum_{j=1}^{6}\beta_j \left (\frac{x_{ji}-\bar{x_j}}{s_j}   \right ) + \varepsilon_{i}\left\{\begin{matrix}
i= 1,\dots,50 \\ 
j=  1,\dots,6
\end{matrix}\right.
$$
\indent
Onde:  $\varepsilon_{i} \overset{i.i.d.}{\sim} N(0,\sigma^2)$ , $x_j=\frac{1}{50}\sum_{i=1}^{50}x_ji$ e  $s_j=\sqrt{\frac{1}{50}\sum_{i=1}^{50}(x_{ji}-\bar{x_j})^2}$

\vspace{0.3cm}
\begin{itemize}
\item $Y_i$ : Expectativa de vida em anos (1969-70).  
\item $\beta_0$ : Expectativa de vida esperada em anos (1969-70) para valores de covariáveis iguais às suas respectivas médias.  
\item $\frac{\beta_1}{s_1}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor da "renda percapita (em 1974 em USD)" em uma unidade, mantendo-se as demais covariáveis fixas.  
\item $\frac{\beta_2}{s_2}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor da "proporção de analfabetos (em 1970)" em uma unidade, mantendo-se as demais covariáveis fixas.  
\item $\frac{\beta_3}{s_3}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor da "taxa de criminalidade (por 100000 habitantes 1976)" em uma unidade, mantendo-se as demais covariáveis fixas.  
\item $\frac{\beta_4}{s_4}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor da "porcentagem
de estudantes que concluem o segundo grau (1970)" em uma unidade, mantendo-se as demais covariáveis fixas.  
\item $\frac{\beta_5}{s_5}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor de "número de dias do ano com temperatura abaixo de zero grau Celsus na cidade mais importante do estado" em uma unidade, mantendo-se as demais covariáveis fixas.  
\item $\frac{\beta_6}{s_6}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor da "densidade da população estimada em julho de 1975 por área do estado em milhas quadradas" em uma unidade, mantendo-se as demais covariáveis fixas.  
\end{itemize}

```{r modelo completo,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#modelo padronizado completo
fit_max <- lm(expvida~1+percap+analf+crime+estud+ndias+dens,data=dados)

res_fit_max = summary(fit_max)
coeff_fit_max = res_fit_max$coefficients
coeff_fit_max = data.frame(round(as.double(coeff_fit_max[,1]),4),round(as.double(coeff_fit_max[,2]),4),round(as.double(coeff_fit_max[,3]),4),ifelse(as.double(coeff_fit_max[,4]) < 0.0001, "<0.0001", round(as.double(coeff_fit_max[,4]),4)))

names(coeff_fit_max)=c("Estimativa","EP","Valor T","Valor p")

#medidas R2 e R2 ajustado do modelo fit_max
R2_fit_max <- round(summary(fit_max)$r.squared,4)
R2aj_fit_max <- round(summary(fit_max)$adj.r.squared,4)
# Estatísticas para comparação de modelos
medidas_fit_max = data.frame(rbind(AIC(fit_max),BIC(fit_max),logLik(fit_max),R2_fit_max,R2aj_fit_max))
colnames(medidas_fit_max)=c("Modelo 1")
rownames(medidas_fit_max)=c("AIC","BIC","Log-Verossimilhança","R2","R2 ajustado")



mm_max = as.matrix(model.matrix(fit_max))



```

Pode-se observar a partir das figuras 2 e 3 que o modelo não teve um ajuste adequado. No gráfico A não observação tendências,o que pode indicar uma independência dos dados. Já no gráfico B, observa-se uma leve heterocedasticidade, dado que entre os valores -2 e -1 de Valores Ajustados vê-se uma discrepâncias entre os resíduos studentizados do que entre os resíduos compreendidos entre os valores de -1 a 2. Porém, um fator de confundimento que pode ser levado em consideração é a flutuação amostral pois o banco de dados possui apenas cinquenta observações. é possível observar uma assimetria positiva no histograma apresentado (gráfico C da figura XX), assim como uma tendencia no gráfico de envelopes (figura XX) o que nos dá indícios de falta de normalidade nos resíduos. Neste caso, deveria-se procurar modelos alternativos que levem em consideração uma distribuição assimétrica. Dado o escopo do curso, procede-se com as análises posteriores.


```{r residuos,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

# !!!acho que seria mais produtivo fazer análise de resíduos apenas para o modelo completo!!!

#grpaficos para análise de resíduos
diag2norm(fit_max)
```
\begin{center}
`r legenda_graf2`
\end{center}

```{r envelope,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#gráfico de envelopes
envelnorm(fit_max)
```

\begin{center}
`r legenda_graf3`
\end{center}

Note, pela tabela 2 (lembrando que os valores da tabela estão arredondados em quatro casas decimais) que somente os parêmetros relacionados às covariáveis "crime", "ndias" e "dens" significativos à um nível de significancia = 0,10. A partir desse resultado, temos a indicação de que um modelo reduzido pode ser mais apropriado. Contudo, desejamos também, obter o modelo que melhor se ajusta aos dados.

\begin{center}
`r legenda_table2`
\end{center}

```{r coeficientes para fit_max,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#pacote para produzir tabela em latex
library(knitr)

# !!! depois editar!!!
#coeficientes e R^2 e R^2 ajustado

kable(coeff_fit_max)

```



3.1 Seleção dos modelos

\vspace{0.3cm}

A técnica escolhida para nos auxiliar a selecionar o modelo normal linear homocedastico que melhor se ajusta aos dados foi a técnica stepwise, veja Azevedo (2016).

```{r modelo intercepto,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#modelo padronizado só com o intercepto
fitmin <- lm(expvida~1,data = dados)
```

```{r stepwisemin,cache = TRUE,echo=FALSE, warning = FALSE,eval = FALSE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf
#eval = FALSE faz com que o R ignore este chunk

#seleção stepwise começando do modelo min (modelo só com o intercepto)
step_min <- step(fitmin,scope = list(upper=fit_max),direction = "both")

```

```{r stepwisemax,cache = TRUE,echo=FALSE, warning = FALSE,eval=FALSE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf
#eval = FALSE faz com que o R ignore este chunk

#seleção stepwise começando do modelo max (modelo com todas as variaveis explicativas)
step_max <- step(fit_max,scope = list(lower=fitmin),direction = "both")

```


A aplicação da metodologia stepwise, començando com o modelo só
com o intercepto ou começando com o modelo completo, indicou,
em ambos os casos que o modelo com que melhor se ajusta é o modelo que leva em consideração somente as covariáveis "crime","estud","ndias" e "dens".

Temos agora o seguinte modelo:

Modelo 2:

$$
Y_i = \beta_0 + \sum_{j=3}^{6}\beta_j \left (\frac{x_{ji}-\bar{x_j}}{s_j}   \right ) + \varepsilon_{i}\left\{\begin{matrix}
i= 1,\dots,50 \\ 
j=  3,\dots,6
\end{matrix}\right.
$$

\indent
Onde  $\varepsilon_{i} \overset{i.i.d.}{\sim} N(0,\sigma^2)$ , $x_j=\frac{1}{50}\sum_{i=1}^{50}x_ji$ e  $s_j=\sqrt{\frac{1}{50}\sum_{i=1}^{50}(x_{ji}-\bar{x_j})^2}$

\vspace{0.3cm}
\begin{itemize}
\item $Y_i$ : Expectativa de vida em anos (1969-70).  
\item $\beta_0$ : Expectativa de vida esperada em anos (1969-70) para valores de covariáveis iguais às suas respectivas médias.  
\item $\frac{\beta_3}{s_3}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor da "taxa de criminalidade (por 100000 habitantes 1976)" em uma unidade, mantendo-se as demais covariáveis fixas.  
\item $\frac{\beta_4}{s_4}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor da "porcentagem de estudantes que concluem o segundo grau (1970)" em uma unidade, mantendo-se as demais covariáveis fixas.  
\item $\frac{\beta_5}{s_5}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor de "número de dias do ano com temperatura abaixo de zero grau Celsus na cidade mais importante do estado" em uma unidade, mantendo-se as demais covariáveis fixas.  
\item $\frac{\beta_6}{s_6}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor da "densidade da população estimada em julho de 1975 por área do estado em milhas quadradas" em uma unidade, mantendo-se as demais covariáveis fixas.
\end{itemize}

```{r Modelo Otimo,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#modelo "ótimo" segundo o stepwise

fit_otimo <- lm(expvida ~ crime + estud + ndias + dens, data = dados)

res_fit_otimo= summary(fit_otimo)
coeff_fit_otimo= res_fit_otimo$coefficients
coeff_fit_otimo= data.frame(round(as.double(coeff_fit_otimo[,1]),4),round(as.double(coeff_fit_otimo[,2]),4),round(as.double(coeff_fit_otimo[,3]),4),ifelse(as.double(coeff_fit_otimo[,4]) < 0.0001, "<0.0001", round(as.double(coeff_fit_otimo[,4]),4)))

names(coeff_fit_otimo)=c("Estimativa","EP","Valor T","Valor p")

#Medidas R2 e R2 ajustado do modelo otimo com intercepto

R2_fit_otimo <- round(summary(fit_otimo)$r.squared,4)
R2aj_fit_otimo <- round(summary(fit_otimo)$adj.r.squared,4)

# Estatísticas para comparação de modelos
medidas_fit_otimo = data.frame(rbind(AIC(fit_otimo),BIC(fit_otimo),logLik(fit_otimo),R2_fit_otimo,R2aj_fit_otimo))
colnames(medidas_fit_otimo)=c("Modelo 2")
rownames(medidas_fit_otimo)=c("AIC","BIC","Log-Verossimilhança","R2","R2 ajustado")
mm = as.matrix(model.matrix(fit_otimo))
```

Em anuência ao ajuste do modelo anterior, este modelo também não apresentou um ajuste adequado, uma vez que se observa nas figuras YY e XX indícios de mal ajuste semelhantes aos observados na análise residual para o modelo anterior. Porém uma ressalva pode ser feita de que no gráfico B pode-se observar que as discrepâncias entre os resíduos mudam conforme o valor ajustado aumenta   
Neste caso, deveria-se procurar modelos alternativos que levem em consideração uma distribuição assimetrica. Novamente, dado o escopo do curso, procede-se com as análises posteriores.

```{r residuos modelo otimo,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#grpaficos para análise de resíduos
diag2norm(fit_otimo)
```

\begin{center}
`r legenda_graf4`
\end{center}

```{r envelope modelo otimo,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#gráfico de envelopes
envelnorm(fit_otimo)
```

\begin{center}
`r legenda_graf5`
\end{center}

Note que a tabela acima acusa que o parâmetro $\beta_0$ não é significativo no modelo para um nível de significância de 0,10. Sendo assim, vamos ajustar o modelo anterior sem intercepto. 

Modelo 3:

$$
Y_i = \sum_{j=3}^{6}\beta_j \left (\frac{x_{ji}-\bar{x_j}}{s_j}   \right ) + \varepsilon_{i}\left\{\begin{matrix}
i= 1,\dots,50 \\ 
j=  3,\dots,6
\end{matrix}\right.
$$
\indent
Onde  $\varepsilon_{i} \overset{i.i.d.}{\sim} N(0,\sigma^2)$ , $x_j=\frac{1}{50}\sum_{i=1}^{50}x_ji$ e  $s_j=\sqrt{\frac{1}{50}\sum_{i=1}^{50}(x_{ji}-\bar{x_j})^2}$

\vspace{0.3cm}
\begin{itemize}
\item$Y_i$ : Expectativa de vida em anos (1969-70).  
\item $\frac{\beta_3}{s_3}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor da "taxa de criminalidade (por 100000 habitantes 1976)" em uma unidade, mantendo-se as demais covariáveis fixas.  

\item $\frac{\beta_4}{s_4}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor da "porcentagem de estudantes que concluem o segundo grau (1970)" em uma unidade, mantendo-se as demais covariáveis fixas.  

\item $\frac{\beta_5}{s_5}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor de "número de dias do ano com temperatura abaixo de zero grau Celsus na cidade mais importante do estado" em uma unidade, mantendo-se as demais covariáveis fixas.  

\item $\frac{\beta_6}{s_6}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor da "densidade da população estimada em julho de 1975 por área do estado em milhas quadradas" em uma unidade, mantendo-se as demais covariáveis fixas. 

\end{itemize}

```{r Modelo Otimo Sem intercepto,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#modelo "ótimo" sem o intercepto

fit_otimoS <- lm(expvida ~ -1 + crime + estud + ndias + dens, data = dados)

res_fit_otimoS= summary(fit_otimoS)
coeff_fit_otimoS= res_fit_otimoS$coefficients
coeff_fit_otimoS= data.frame(round(as.double(coeff_fit_otimoS[,1]),4),round(as.double(coeff_fit_otimoS[,2]),4),round(as.double(coeff_fit_otimoS[,3]),4),ifelse(as.double(coeff_fit_otimoS[,4]) < 0.0001, "<0.0001", round(as.double(coeff_fit_otimoS[,4]),4)))

names(coeff_fit_otimoS)=c("Estimativa","EP","Valor T","Valor p")

#Medidas R2 e R2 ajustado do modelo otimo sem intercepto
R2_fit_otimoS <- round(summary(fit_otimoS)$r.squared,4)
R2aj_fit_otimoS <- round(summary(fit_otimoS)$adj.r.squared,4)

# Estatísticas para comparação de modelos
medidas_fit_otimoS = data.frame(rbind(AIC(fit_otimoS),BIC(fit_otimoS),logLik(fit_otimoS),R2_fit_otimoS,R2aj_fit_otimoS))
colnames(medidas_fit_otimoS)=c("Modelo 3")
rownames(medidas_fit_otimoS)=c("AIC","BIC","Log-Verossimilhança","R2","R2 ajustado")

mm = as.matrix(model.matrix(fit_otimoS))
```



```{r residuos modelo otimo sem intercepto,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#grpaficos para análise de resíduos
diag2norm(fit_otimoS)
```

\begin{center}
`r legenda_graf6`
\end{center}

```{r envelope modelo otimo sem intercepto,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#gráfico de envelopes
envelnorm(fit_otimoS)
```

\begin{center}
`r legenda_graf7`
\end{center}

A tabela XX abaixo mostra as principais medidas de comparação entre os dois últimos modelos (com e sem intercepto). Observamos nela, valores menores de AIC e BIC para o modelo sem intercepto, o que nos da uma indicação de que o modelo sem intercepto é preferível.

\begin{center}
`r legenda_table3`
\end{center}
```{r comparacao modelo otimo c e s intercepto,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
library(knitr)
#dados para gerar a tabela de comparação dos modelos com e sem intercepto
tbl_comparacao <- cbind(medidas_fit_otimo,medidas_fit_otimoS)
as.data.frame(tbl_comparacao)
```


#Multicolinearidade

Mesmo o modelo não apresentando muitas covariáveis, é interessante, a fim de assegurar a validade dos resultados obtidos (desconsidere que o modelo não teve um bom ajuste), verificar também a possibilidade de se ter multicolinearidade presente no modelo ajustado. Com o propósito de identificar alguma indicação de multicolinearidade no modelo, podemos análisar os coeficiêntes de corelação linear entre as covariáveis "crime", "estud", "ndias" e "dens". Porém, observamos na tabela XX (abaixo) que nenhum par de covariáveis apresenta coeficiente de correlação deveras alto, assim como a natureza das covariáveis presentes no medelo não apresentarem nenhum indício de serem fontes de multicolinearidade.

\begin{center}
`r legenda_table4`
\end{center}
```{r,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#Análise de multicolineariedade descritivamente

#pegando só as variáveis do modelo otimo
dados_modelo_otimo <- dados[,3:6]
cor(dados_modelo_otimo)

#Verificação dos autovalores

autval <- eigen(t(mm) %*% mm)$values
indcond <- round(max(autval)/min(autval),4)


```

Além disso, Sabe-se que se a razão entre o maior autovalor ($\lambda_{max}$) e o menor ($\lambda_{min}$) (o chamado índice de condição) $K=\frac{\lambda_{max}}{\lambda_{min}}$ for maior que mil, geralmente, há indicios de multicolinearidade. Fazendo isso para o caso do problema em questão, tem-se que: $K=$ `r indcond`. Como $K < 1000$, portanto descartaremos a hipótese de multicolinearidade dos dados.


#Alavancagem

Observando a figura XX podemos identificar a existência de pontos distantes dos demais, o que é uma indicação de alavancagem.

```{r alavancagem,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#medidas de influência e alavancagem

anainflu_norm(fit_otimoS)
```
\begin{center}
`r legenda_graf8`
\end{center}


```{r valores_alavancagem, cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
valores = anainflu_ind(fit_otimoS)

indh = as.integer(valores[1])

vh = as.double(valores[2])

inddi1 = as.integer(valores[3])

inddi2 = as.integer(valores[4])

vdi1 = as.double(valores[5])

vdi2 = as.double(valores[6])

```

Vemos para o gráfico de Medida h, o ponto que se destaca é o de indice `r indh`, com valor de `r vh`. Já no de Distânca de Cook, temos dois pontos em destaque: um é o do mesmo indice,com valor `r vdi2`, coomparações entre os valores das duas medidas não consistentes e portanto inválidas, outro ponto é o de indice `r inddi1`, com valor `r vdi1`.

Logo, como identificamos esses pontos, vamos montar um modelo reduzido, como feito acima mas excluindo primeiramente as observações de indice 40 pois nos dois caso é o ponto mais elevado, possívelmente o que mais influência no modelo. caso ocorra uma melhora de ajuste, faremos para o outro identificado pela Distância de Cook.

Segue abaixo o ajuste do modelo sem aa observações 11 e 40

```{r fit_otimoS_adj1,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}

fit_otimoS_adj1 <- lm(expvida ~ -1 + crime + estud + ndias + dens, data = dados[-c(11,40),])


res_fit_otimoS_adj1 = summary(fit_otimoS_adj1)
coeff_fit_otimoS_adj1 = res_fit_otimoS_adj1$coefficients
coeff_fit_otimoS_adj1 = data.frame(round(as.double(coeff_fit_otimoS_adj1[,1]),4),round(as.double(coeff_fit_otimoS_adj1[,2]),4),round(as.double(coeff_fit_otimoS_adj1[,3]),4),ifelse(as.double(coeff_fit_otimoS_adj1[,4]) < 0.0001, "<0.0001", round(as.double(coeff_fit_otimoS_adj1[,4]),4)))

names(coeff_fit_otimoS_adj1)=c("Estimativa","EP","Valor T","Valor p")

#Medidas R2 e R2 ajustado do modelo fit_otimoS_adj1
R2_fit_otimoS_adj1 <- round(summary(fit_otimoS_adj1)$r.squared,4)
R2aj_fit_otimoS_adj1 <- round(summary(fit_otimoS_adj1)$adj.r.squared,4)
# Estatísticas para comparação de modelos
medidas_fit_otimoS_adj1 = data.frame(rbind(AIC(fit_otimoS_adj1),BIC(fit_otimoS_adj1),logLik(fit_otimoS_adj1),R2_fit_otimoS_adj1,R2aj_fit_otimoS_adj1))
colnames(medidas_fit_otimoS_adj1)=c("Modelo 4")
rownames(medidas_fit_otimoS_adj1)=c("AIC","BIC","Log-Verossimilhança","R2","R2 ajustado")



mm_adj1 = as.matrix(model.matrix(fit_otimoS_adj1))
```

```{r residuos modelo otimo ajustado 1,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#grpaficos para análise de resíduos
diag2norm(fit_otimoS_adj1)
```
\begin{center}
`r legenda_graf9`
\end{center}

```{r envelope modelo otimo ajustado 1,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#gráfico de envelopes
envelnorm(fit_otimoS_adj1)
```
\begin{center}
`r legenda_graf10`
\end{center}

```{r fit_otimoS_adj2,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}

fit_otimoS_adj2 <- lm(expvida ~ -1 + crime + estud + ndias + dens, data = dados[-c(11,40),])

res_fit_otimoS_adj2 = summary(fit_otimoS_adj2)
coeff_fit_otimoS_adj2 = res_fit_otimoS_adj2$coefficients
coeff_fit_otimoS_adj2 = data.frame(round(as.double(coeff_fit_otimoS_adj2[,1]),4),round(as.double(coeff_fit_otimoS_adj2[,2]),4),round(as.double(coeff_fit_otimoS_adj2[,3]),4),ifelse(as.double(coeff_fit_otimoS_adj2[,4]) < 0.0001, "<0.0001", round(as.double(coeff_fit_otimoS_adj2[,4]),4)))

names(coeff_fit_otimoS_adj1)=c("Estimativa","EP","Valor T","Valor p")

#Medidas R2 e R2 ajustado do modelo fit_otimoS_adj2
R2_fit_otimoS_adj2 <- round(summary(fit_otimoS_adj2)$r.squared,4)
R2aj_fit_otimoS_adj2 <- round(summary(fit_otimoS_adj2)$adj.r.squared,4)

# Estatísticas para comparação de modelos
medidas_fit_otimoS_adj2 = data.frame(rbind(AIC(fit_otimoS_adj2),BIC(fit_otimoS_adj2),logLik(fit_otimoS_adj2),R2_fit_otimoS_adj2,R2aj_fit_otimoS_adj2))
colnames(medidas_fit_otimoS_adj2)=c("Modelo 5")
rownames(medidas_fit_otimoS_adj2)=c("AIC","BIC","Log-Verossimilhança","R2","R2 ajustado")



mm_adj1 = as.matrix(model.matrix(fit_otimoS_adj1))
```

```{r residuos modelo otimo ajustado 2,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#grpaficos para análise de resíduos
diag2norm(fit_otimoS_adj2)
```
\begin{center}
`r legenda_graf11`
\end{center}

```{r envelope modelo otimo ajustado 2,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#gráfico de envelopes
envelnorm(fit_otimoS_adj2)
```
\begin{center}
`r legenda_graf12`
\end{center}

\begin{center}
`r legenda_table5`
\end{center}
```{r tabela de comparcao modelos,cache = TRUE,echo=FALSE, warning = FALSE,eval=TRUE,message = FALSE}
#medidas_fit_max
#medidas_fit_otimo
#medidas_fit_otimoS
#medidas_fit_otimoS_adj1
#medidas_fit_otimoS_adj2

medidas_comp_model = data.frame(medidas_fit_max,medidas_fit_otimo,medidas_fit_otimoS, medidas_fit_otimoS_adj1,medidas_fit_otimoS_adj2)

medidas_comp_model

```

\newpage
\vspace{0.5cm}
\begin{enumerate}
\setcounter{enumi}{3}
\item Conclusões
\end{enumerate}
\vspace{0.3cm}

Como visto, nenhum modelo destes propostos teve um bom ajuste ao conjunto de dados não obstante utilizaremos o modelo quatro pois é o que apresenta as  melhores estimativas de comparação de modelo, ou seja baixo AIC E BIC, alta Log-Verossimilhança. Podemos observar também que há uma relaç

\vspace{0.5cm}
\begin{enumerate}
\setcounter{enumi}{4}
\item Referências Bibliográficas
\end{enumerate}

\vspace{0.3cm}
\begin{itemize}
  \item Azevedo, C. L. N (2016). Notas de aula sobre planejamento e análise de experimentos,\url{http://www.ime.unicamp.br/~cnaber/Material_ME613_2S_20
16.htm}
  \item Faraway, J. J. (2014). Linear Models with R, Second Edition,Chapman e Hall/CRC Texts in Statistical Science
  \item Draper, N. R. and Smith, H. (1998). Applied regression analysis, third edition. New York, NY: John Wiley e Sons.
  \item Paula, G. A. (2013). Modelos de regressão com apoio computacional, versão pré-eliminar \url{https://www.ime.usp.br/~giapaula/texto_2013.pdf}
  
\end{itemize}

\vspace{0.5cm}
