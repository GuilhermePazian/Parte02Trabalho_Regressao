---
title: "trabalho Regressão parte 02"
date: "6 de dezembro de 2016"
output: pdf_document
---

```{r pacotes,cache = TRUE,echo=FALSE, warning = FALSE, error = FALSE}
#eval= FALSE faz com que o R ignore este chunk
#echo = FALSE não permite que o chunk apareça no pdf

#pacotes = c("tidyverse","plyr","dplyr","reshape2","knitr")
#install.packages(pacotes)

# pacote utiliado para gráficos
library(ggplot2)
# pacote que deixa os gráficos do ggplot lado a lado
library(gridExtra)
# pacotes para manipulação de dados
library(reshape2)
library(plyr)
library(dplyr)
#pacote que possui o conjunto de dados para o primeiro exercício
library(car)
#pacote para fazer legenda
library(captioner)



figs <- captioner(prefix="Figura")
tbls <- captioner(prefix="Tabela")

#inslação dos pacotes necessários
#install.packages(C("tidyverse","gridExtra","car","captioner","gvlma"))

#instalacao de um pacote pra "printar" tabelas mais bonitinhas
#install.packages(
#  'printr',
#  type = 'source',
#  repos = c('http://yihui.name/xran', 'http://cran.rstudio.com')
#)

```

```{r legendas, echo=FALSE, cache=TRUE}
#legenda para as tabelas

# legenda para a primeira tabela(estats descr) do primeiro exercício
legenda_table1 = tbls(name="table_estat_descr1",caption = "Estatísticas Descritivas")
legenda_table2 = tbls(name="table_esti_testedenulidade",caption = "Estimativas dos parâmetros, intervalo de confiança e teste de nulidade")


#legendas para os gráficos

#legenda para o primeiro Boxplot
legenda_graf1 = figs(name="graf1_boxplot",caption = "Boxplot Comparativo")
#legenda para o primeiro grárico de dispersão
legenda_graf2 = figs(name="graf2_dispersao",caption = "Dispersão entre as variáveis Altura e Peso")
legenda_graf3 = figs(name="graf3_dispersao",caption = "Dispersão entre as variáveis Altura e Peso considerando o sexo.")
legenda_graf4 = figs(name="graf4_analiseresidual",caption = "Análise residual para o modelo 1")
legenda_graf5 = figs(name="graf5_envelope",caption = "Gráfico de envelope para o resíduos studentizado para o modelo 1")
legenda_graf6 = figs(name="graf6_analiseresidual",caption = "Análise residual para o modelo 2")
legenda_graf7 = figs(name="graf7_envelope",caption = "Gráfico de envelope para o resíduos studentizado para o modelo 2")
legenda_graf8 = figs(name="graf8_analiseresidual",caption = "Análise residual para o modelo 3")
legenda_graf9 = figs(name="graf9_envelope",caption = "Gráfico de envelope para o resíduos studentizado para o modelo 3")
legenda_graf10 = figs(name="graf10_analiseresidual",caption = "Análise residual para o modelo 4")
legenda_graf11 = figs(name="graf11_envelope",caption = "Gráfico de envelope para o resíduos studentizado para o modelo 4")

```




```{r Funcoes,echo=FALSE,warning=FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#Função que produz os quatro gráficos para a análise de resíduos
diag2norm<-function(fit.model){
# fit.model: objeto com o ajuste do modelo normal linear homocedástico 
# obtido através da função "lm"

X <- model.matrix(fit.model)
n <- nrow(X)
p <- ncol(X)
H <- X%*%solve(t(X)%*%X)%*%t(X)
h <- diag(H)
lms <- summary(fit.model)
s <- lms$sigma
r <- resid(lms)
ts <- r/(s*sqrt(1-h))
di <- (1/p)*(h/(1-h))*(ts^2)
si <- lm.influence(fit.model)$sigma
tsi <- r/(si*sqrt(1-h))
tam <- 1:length(tsi)
a <- max(tsi)
b <- min(tsi)

g1 = ggplot(data=data.frame(tam,tsi),aes(tam,tsi))+ geom_point() +scale_y_continuous(name = "Resíduo Studentizado",limits=c(b-1,a+1)) +scale_x_continuous(name = "Índice")+labs(title="A")+geom_hline(yintercept=0,size=0.25,linetype=2)+geom_hline(yintercept=2,size=0.25,linetype=2)+geom_hline(yintercept=-2,size=0.25,linetype=2)+theme_light()

g2 =  ggplot(data=data.frame(fitted(fit.model),tsi),aes(fitted(fit.model),tsi))+ geom_point() +scale_y_continuous(name = "Resíduo Studentizado",limits=c(b-1,a+1)) +scale_x_continuous(name = "Valores Ajustados")+labs(title="A")+geom_hline(yintercept=0,size=0.25,linetype=2)+geom_hline(yintercept=2,size=0.25,linetype=2)+geom_hline(yintercept=-2,size=0.25,linetype=2)+theme_light()

#Histograma
g3 = ggplot(data=data.frame(tsi),aes(tsi,col=I("black"),fill=I("white")))+geom_histogram(binwidth = 1,aes(y=..density..))+labs(title="C",x="Resíduo Studentizado",y="Densidade")+theme_light()

#Boxplot
g4 = ggplot(data=data.frame(fac = factor(1),tsi),aes(fac,tsi,col=I("black"),fill=I("white")))+ geom_boxplot(outlier.size = 2.5, outlier.colour = "red",width=0.4)+scale_x_discrete(name="")+scale_y_continuous(name = "Residuo Studentizado")+theme(axis.text.x = element_blank())+theme_light()

#funcao que une todos os gráficos
grid.arrange(g1,g2,g3,g4,ncol=2,nrow=2)
#---------------------------------------------------------------#

}

# Programa extraído do site: https://www.ime.usp.br/~giapaula/textoregressao.htm
# Créditos: Prof. Dr. Gilberto Alvarenga Paula
# Adaptado por Caio L. N. Azevedo e Henrique Capatto

envelnorm<-function(fit.model){  
# argumento: modelo de regressão linear homocedástico ajustado
# Eu adaptei uma função que achei na net com o que o Caio fez nos grafs de envelope. Agradeçam a um desconhecido.  

  
  
    X <- model.matrix(fit.model)
    n <- nrow(X)
    p <- ncol(X)
    H <- X%*%solve(t(X)%*%X)%*%t(X)
    h <- diag(H)
    si <- lm.influence(fit.model)$sigma
    r <- resid(fit.model)
    tsi <- r/(si*sqrt(1-h))
    #
    ident <- diag(n)
    epsilon <- matrix(0,n,100)
    e <- matrix(0,n,100)
    e1 <- numeric(n)
    e2 <- numeric(n)
    #
    for(i in 1:100){
        epsilon[,i] <- rnorm(n,0,1)
        e[,i] <- (ident - H)%*%epsilon[,i]
        u <- diag(ident - H)
        e[,i] <- e[,i]/sqrt(u)
        e[,i] <- sort(e[,i]) }
    #
    for(i in 1:n){
        eo <- sort(e[i,])
        e1[i] <- (eo[2]+eo[3])/2
        e2[i] <- (eo[97]+eo[98])/2 }
  
  
    y <- quantile(tsi[!is.na(tsi)], c(0.25, 0.75))
    x <- qnorm(c(0.25, 0.75))
    slope <- diff(y)/diff(x)
    int <- y[1L] - slope * x[1L]
  
    d <- data.frame(resids = tsi)
  
    ggplot(d, aes(sample = resids))+stat_qq()+stat_qq(aes(sample=e1),geom="line")+stat_qq(aes(sample=e2),geom="line")+ geom_abline(slope = slope, intercept = int,linetype = 3)+labs(x="Percentil da N(0,1)",y="Residuo Studentizado",title="E")+theme_light()
}




#função para "medidas de influência e alavancagem"




anainflu_norm<-function(fit.model){
# fit.model: objeto com o ajuste do modelo normal linear homocedástico 
# obtido através da função "lm"
X <- model.matrix(fit.model)
n <- nrow(X)
p <- ncol(X)
H <- X%*%solve(t(X)%*%X)%*%t(X)
h <- diag(H)
lms <- summary(fit.model)
s <- lms$sigma
r <- resid(lms)
ts <- r/(s*sqrt(1-h))
di <- (1/p)*(h/(1-h))*(ts^2)
si <- lm.influence(fit.model)$sigma
tsi <- r/(si*sqrt(1-h))
a <- max(tsi)
b <- min(tsi)
par(mfrow=c(1,2))
plot(h,xlab="Índice", ylab="Medida h", pch=16, ylim=c(0,1),cex=1.1,cex.axis=1.1,cex.lab=1.1)
cut <- 2*p/n
abline(cut,0,lty=2)
#identify(h, n=1)
#title(sub="(a)")
#
plot(di,xlab="Índice", ylab="Distância de Cook", pch=16,cex=1.1,cex.axis=1.1,cex.lab=1.1)
#identify(di, n=2)
#
#------------------------------------------------------------#
}

anainflu_ind = function(fit.model){ 
# fit.model: objeto com o ajuste do modelo normal linear homocedástico 
# obtido através da função "lm"
X <- model.matrix(fit.model)
n <- nrow(X)
p <- ncol(X)
H <- X%*%solve(t(X)%*%X)%*%t(X)
h <- diag(H)
lms <- summary(fit.model)
s <- lms$sigma
r <- resid(lms)
ts <- r/(s*sqrt(1-h))
di <- (1/p)*(h/(1-h))*(ts^2)

maxh = as.integer(which.max(h))

maxdi = as.integer(which(di > 0.15))

maxs = list(maxh,as.double(h[maxh]),maxdi[1],maxdi[2],as.double(di[maxdi][1]),as.double(di[maxdi][2]))

return(maxs)
}

```

#Introdução

Este presente trabalho é parte do escopo da disciplina ME613 - Regressão Linear e visa a aplicação dos conhecimentos adquiridos em sala de aula. Grande parte do trabalho foi baseado e adaptado a partir dos materiais disponibilizados na página do curso: [http://www.ime.unicamp.br/~cnaber/Material_ME613_2S_2016.htm]("http://www.ime.unicamp.br/~cnaber/Material_ME613_2S_2016.htm").  
O conjunto de dados a ser analisado está disponível em na página do curso sob o nome "reg3.dat". Neste são  descritas as seguintes variáveis referentes a 50 estados norte-americanos: (i) **estado** (nome do estado), (ii) **pop** (população estimada em julho de 1975), (iii) **percap** (renda percapita em 1974 em USD), (iv) **analf** (proporção de analfabetos em 1970), (v) **expvida** (expectativa de vida em anos 1969-70), (vi) **crime** (taxa de criminalidade por 100000 habitantes 1976), (vii) **estud** (porcentagem de estudantes que concluem o segundo grau 1970), (viii) **ndias** (número de dias do ano com temperatura abaixo de zero grau Celsus na cidade mais importante do estado) e (ix) **area** (área do estado em milhas quadradas). O objetivo do estudo é tentar explicar a variável **expvida** usando um modelo de regressão normal linear dadas as variáveis explicativas **percap**, **analf**, **crime**, **estud**, **ndias** e **dens**, em que **dens**=pop/area (densidade da população estimada em julho de 1975 por área do estado em milhas quadradas).  
Todos os modelos neste trabalho foram ajustados via metodologia de mínimos quadrados ordinários, veja Azevedo (2016), e todas suas respectivas análises residuais foram realizadas, conforme Paula (2013).
A menos que seja citado o contrário, todas as variáveis que constam na base de dados serão referidas por sua descrição completa ou pelo nome que consta no banco de dados (estes foram supracitados em negrito). Denotaremos também:
  
$Y_i$ - i-ésima observação da variável expvida  
$x_{1i}$ - i-esima observação da variável percap  
$x_{2i}$ - i-esima observação da variável analf  
$x_{3i}$ - i-esima observação da variável crime  
$x_{4i}$ - i-esima observação da variável estud  
$x_{5i}$ - i-esima observação da variável ndias  
$x_{6i}$ - i-esima observação da variável dens  



```{r leitura,echo = FALSE,warning=FALSE}
#echo = FALSE não permite que o chunk apareça no pdf
library(plyr)
library(tidyverse)
library(dplyr)

#leitura dos dados

dados = read.table("http://www.ime.unicamp.br/~cnaber/reg3.dat")
names(dados)=c("Estado","pop","percap","analf","expvida","crime","estud","ndias","area")

#criação variável dens
dados = dados %>% mutate(dens=pop/area)

#seleção das variáveis segundo orientação do Caio
dados = dados %>% select(percap, analf, crime, estud, ndias,dens,expvida)
```

#2.Análise Descritiva

```{r descritivas,echo = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

library(reshape2)
library(printr)

#manipulação dos dados

estat_desc <- dados
estat_desc$Estado = NULL

df <- melt(estat_desc, id.vars = 0)

#tabela resumo

resumo <- ddply(df, c("variable"), function(x) summary(x$value))
#arredondando os valores !!! tentar arredondar os decimais porem manter os discretos com somente o valor!!!
resumo[,2:ncol(resumo)] <- round(resumo[,2:ncol(resumo)],4)
resumo
```


```{r boxplots,echo = FALSE,eval=FALSE}
#echo = FALSE não permite que o chunk apareça no pdf
#eval= FALSE faz com que o R ignore este chunk

# !!!acho que boxplots não são nescessários neste caso, já que temos todas as variáveis contínuas (ou discretas), ou seja, nenhum fator!!!

#boxplots
ggplot(df, aes(x = variable, y =  value)) +
  geom_boxplot() +
  facet_wrap(~variable, scales = "free") +  theme_bw()
```

Dado a natureza quantitativa dos dados, é de grande interesse que identifiquemos as relações entre as covariáveis explicativas e a variável resposta, a fim de tornar essas relações visuais, foi construido graficos de dispersão entre a variável resposta e entre todas as covariáveis de interesse. Estes estão representados na figura XX. 

```{r dispersao,echo = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#gráficos de dispersão
dispersao <- melt(estat_desc, id.vars = 7)
ggplot(dispersao, aes(x = value, y =  expvida)) +
  geom_point() +
  facet_wrap(~variable, scales = "free") +  theme_bw()
```

A partir da FiguraXX, podemos identificar visualmente a relação supracitada, a qual identificamos que todas as covariáveis parecem ter uma relação linear significativa, as quais existem relações lineares negativas entre a variável resposta e as covariáveis "analf" e "crime", assim como relações lineares negativas entre a variável resposta "expvida" e as covariáveis "percap","estud","ndias" e "dens" (a menos a um ponto).



#Análise Inferêncial


```{r padronizacao,echo = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf


#Padronizacao dos dados
dados[,c(1:ncol(dados))] =  sapply(dados[,c(1:ncol(dados))], function(x) (x-mean(x))/sd(x))

```

Dada a constatação visual de relações lineares entre a variável resposta "expvida" e todas as covariáveis explicativas, é razoável iniciar um modelo que contemple todas estas covariáveis. Visando poder comparar diretamente os coeficiêntes do modelo, optamos por introduzir as covariáveis com médias e variâncias iguais, tornardo-as adimensionais. Portanto, vamos iniciar a análise com o seguinte modelo:

Modelo: !!!note que pode-se resumir a interpretação de $B_j/s_j$ caso precise de espeço!!!
$$
Y_i = \beta_0 + \sum_{j=1}^{6}\beta_j \left (\frac{x_{ji}-\bar{x_j}}{s_j}   \right ) + \varepsilon_{i}\left\{\begin{matrix}
i= 1,\dots,50 \\ 
j=  1,\dots,6
\end{matrix}\right.
$$
em que  $\varepsilon_{i} \overset{i.i.d.}{\sim} N(0,\sigma^2)$ , $x_j=\frac{1}{50}\sum_{i=1}^{50}x_ji$ e  $s_j=\sqrt{\frac{1}{50}\sum_{i=1}^{50}(x_{ji}-\bar{x_j})^2}$

$Y_i$ : Expectativa de vida em anos (1969-70).  
$\beta_0$ : Expectativa de vida esperada em anos (1969-70) para valores de covariáveis iguais às suas respectivas médias.  
$\frac{\beta_1}{s_1}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor da "renda percapita (em 1974 em USD)" em uma unidade, mantendo-se as demais covariáveis fixas.  
$\frac{\beta_2}{s_2}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor da "proporção de analfabetos (em 1970)" em uma unidade, mantendo-se as demais covariáveis fixas.  
$\frac{\beta_3}{s_3}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor da "taxa de criminalidade (por 100000 habitantes 1976)" em uma unidade, mantendo-se as demais covariáveis fixas.  
$\frac{\beta_4}{s_4}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor da "porcentagem
de estudantes que concluem o segundo grau (1970)" em uma unidade, mantendo-se as demais covariáveis fixas.  
$\frac{\beta_5}{s_5}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor de "número de dias do ano com temperatura abaixo de zero grau Celsus na cidade mais importante do estado" em uma unidade, mantendo-se as demais covariáveis fixas.  
$\frac{\beta_6}{s_6}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor da "densidade da população estimada em julho de 1975 por área do estado em milhas quadradas" em uma unidade, mantendo-se as demais covariáveis fixas.  

```{r modelo completo,echo = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#modelo padronizado completo
fitmax <- lm(expvida~+percap+analf+crime+estud+ndias+dens,data=dados)

res_fit_max = summary(fitmax)
coeff_fit_max = res_fit_max$coefficients
coeff_fit_max = data.frame(round(as.double(coeff_fit_max[,1]),4),round(as.double(coeff_fit_max[,2]),4),round(as.double(coeff_fit_max[,3]),4),ifelse(as.double(coeff_fit_max[,4]) < 0.0001, "<0.0001", round(as.double(coeff_fit_max[,4]),4)))

names(coeff_fit_max)=c("Estimativa","EP","Valor T","Valor p")

# Estatísticas para comparação de modelos
medidas_fit_max = data.frame(rbind(AIC(fitmax),BIC(fitmax),logLik(fitmax)))
colnames(medidas_fit_max)=c("Modelo 1")
rownames(medidas_fit_max)=c("AIC","BIC","Log-Verossimilhança")



mm_max = as.matrix(model.matrix(fitmax))



```
Pode-se observar a partir das figuras XX e XX que o modelo não teve um ajuste adequado, uma vez que se é possível observar uma assimetria positiva no histograma apresentado (gráfico YY da figura XX), assim como uma tendencia no gráfico de envelopes (figura XX) o que nos dá indícios de falta de normalidade nos resíduos. **!!!eu não identifiquei heterocedasticidade, se alguem achar que têm, escreva algum argumento!!!**. Neste caso, deveria-se procurar modelos alternativos que levem em consideração uma distribuição assimetrica. Dado o escopo do curso, procede-se com as análises posteriores.




```{r residuos,echo = FALSE,warning = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

# !!!acho que seria mais produtivo fazer análise de resíduos apenas para o modelo completo!!!

#grpaficos para análise de resíduos
diag2norm(fitmax)
```

```{r envelope,echo = FALSE,warning = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#gráfico de envelopes
envelnorm(fitmax)
```
Note, pela tabela XX que somente os parêmetros relacionados às covariáveis "crime", "ndias" e "dens" significativos à um nível de significancia =0,10. A partir desse resultado, temos a indicação de que um modelo reduzido pode ser mais apropriado. Contudo, desejamos também, obter o modelo que melhor se ajusta aos dados.

```{r}
#pacote para produzir tabela em latex
library(knitr)

# !!! depois editar!!!
#coeficientes e R^2 e R^2 ajustado
R2fitmax <- summary(fitmax)$r.squared
R2fitmax
R2aj_fitmax <- summary(fitmax)$adj.r.squared
R2aj_fitmax
kable(summary(fitmax)$coefficients)

```

#Seleção dos modelos
A técnica escolhida para nos auxiliar a selecionar o modelo normal linear homocedastico que melhor se ajusta aos dados foi a técnica stepwise, veja Azevedo (2016).

```{r modelo intercepto,echo = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#modelo padronizado só com o intercepto
fitmin <- lm(expvida~1,data = dados)
```

```{r stepwisemin,echo = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#seleção stepwise começando do modelo min (modelo só com o intercepto)
step_min <- step(fitmin,scope = list(upper=fitmax),direction = "both")

```


```{r stepwisemax,echo = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf


#seleção stepwise começando do modelo max (modelo com todas as variaveis explicativas)
step_max <- step(fitmax,scope = list(lower=fitmin),direction = "both")

```


A aplicação da metodologia stepwise, començando com o modelo só
com o intercepto ou começando com o modelo completo, indicou,
em ambos os casos que o modelo com que melhor se ajusta é o modelo que leva em consideração somente as covariáveis "crime","estud","ndias" e "dens".

Temos agora o seguinte modelo:

$$
Y_i = \beta_0 + \sum_{j=3}^{6}\beta_j \left (\frac{x_{ji}-\bar{x_j}}{s_j}   \right ) + \varepsilon_{i}\left\{\begin{matrix}
i= 1,\dots,50 \\ 
j=  3,\dots,6
\end{matrix}\right.
$$
em que  $\varepsilon_{i} \overset{i.i.d.}{\sim} N(0,\sigma^2)$ , $x_j=\frac{1}{50}\sum_{i=1}^{50}x_ji$ e  $s_j=\sqrt{\frac{1}{50}\sum_{i=1}^{50}(x_{ji}-\bar{x_j})^2}$

$Y_i$ : Expectativa de vida em anos (1969-70).  
$\beta_0$ : Expectativa de vida esperada em anos (1969-70) para valores de covariáveis iguais às suas respectivas médias.  
$\frac{\beta_3}{s_3}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor da "taxa de criminalidade (por 100000 habitantes 1976)" em uma unidade, mantendo-se as demais covariáveis fixas.  
$\frac{\beta_4}{s_4}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor da "porcentagem de estudantes que concluem o segundo grau (1970)" em uma unidade, mantendo-se as demais covariáveis fixas.  
$\frac{\beta_5}{s_5}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor de "número de dias do ano com temperatura abaixo de zero grau Celsus na cidade mais importante do estado" em uma unidade, mantendo-se as demais covariáveis fixas.  
$\frac{\beta_6}{s_6}$ : Incremento (positivo ou negativo) na expectativa de vida em anos (1969-70) esperada quando se aumenta o valor da "densidade da população estimada em julho de 1975 por área do estado em milhas quadradas" em uma unidade, mantendo-se as demais covariáveis fixas.

```{r Modelo Otimo,echo = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#modelo "ótimo" segundo o stepwise

fit_otimo <- lm(expvida ~ crime + estud + ndias + dens, data = dados)

res_fit_otimo= summary(fit_otimo)
coeff_fit_otimo= res_fit_otimo$coefficients
coeff_fit_otimo= data.frame(round(as.double(coeff_fit_otimo[,1]),4),round(as.double(coeff_fit_otimo[,2]),4),round(as.double(coeff_fit_otimo[,3]),4),ifelse(as.double(coeff_fit_otimo[,4]) < 0.0001, "<0.0001", round(as.double(coeff_fit_otimo[,4]),4)))

names(coeff_fit_otimo)=c("Estimativa","EP","Valor T","Valor p")

# Estatísticas para comparação de modelos
medidas_fit_otimo = data.frame(rbind(AIC(fit_otimo),BIC(fit_otimo),logLik(fit_otimo)))
colnames(medidas_fit_otimo)=c("Modelo 2")
rownames(medidas_fit_otimo)=c("AIC","BIC","Log-Verossimilhança")

mm = as.matrix(model.matrix(fit_otimo))
```

Em anuência ao ajuste do modelo anterior, este modelo também não apresentou um ajuste adequado, uma vez que se observa nas figuras YY XX indícios de mal ajuste semelhantes aos observados na análise residual para o modelo anterior. **!!! alguém identificou algum problema a mais??? argumentar aqui!!!** 
Neste caso, deveria-se procurar modelos alternativos que levem em consideração uma distribuição assimetrica. Novamente, dado o escopo do curso, procede-se com as análises posteriores.

```{r residuos modelo otimo,echo = FALSE,warning=FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#grpaficos para análise de resíduos
diag2norm(fit_otimo)
```

```{r envelope modelo otimo,echo = FALSE,warning=FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#gráfico de envelopes
envelnorm(fit_otimo)
```


```{r,echo=FALSE}
#coeficientes modelo otimo

#!!!Editar essa tabela!!!

R2fit_otimo <- summary(fit_otimo)$r.squared
R2aj_fit_otimo <- summary(fit_otimo)$adj.r.squared
kable(summary(fit_otimo)$coefficients)
```

#Multicolinearidade

Mesmo o modelo não apresentando muitas covariáveis, é interessante, a fim de assegurar a validade dos resultados obtidos (desconsidere que o modelo não teve um bom ajuste), verificar também a possibilidade de se ter multicolinearidade presente no modelo ajustado. Com o propósito de identificar alguma indicação de multicolinearidade no modelo, podemos análisar os coeficiêntes de corelação linear entre as covariáveis "crime", "estud", "ndias" e "dens". Porém, observamos na tabela XX (abaixo) que nenhum par de covariáveis apresenta coeficiente de correlação deveras alto. Este fato, somado ao fato das covariáveis presentes no medelo não apresentarem nenhum indício de serem fontes de multicolinearidade, descartamos então, a hipótese de presença de multicolinearidade no modelo.


```{r,echo=FALSE}
#Análise de multicolineariedade descritivamente

#pegando só as variáveis do modelo otimo
dados_modelo_otimo <- dados[,3:6]
cor(dados_modelo_otimo)

#Verificação dos autovalores

autval <- eigen(t(mm) %*% mm)$values
indcond <- max(autval)/min(autval)


```

Sabe-se que se a divisão $K=\frac{\lambda_{max}}{\lambda_{min}}$ for maior que mil, geralmente, há indicios de multicolinearidade. Fazendo isso para o caso do problema em questão, tem-se que: $K=$ `r indcond`. Como $K < 1000$, descartaremos a hipótese de multicolinearidade dos dados.


#Alavancagem

Observando a figura XX podemos identificar a existência de pontos distantes dos demais, o que é uma indicação de alavancagem.

**!!!escrever explicaçõs, identificar os pontos e depois ajustar modelos sem estes pontos e compara-los via AIC e BIC!!!**

```{r alavancagem,echo = FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#medidas de influência e alavancagem

anainflu_norm(fit_otimo)
```



```{r valores_alavancagem, echo=FALSE}
valores = anainflu_ind(fit_otimo)

indh = as.integer(valores[1])

vh = as.double(valores[2])

inddi1 = as.integer(valores[3])

inddi2 = as.integer(valores[4])

vdi1 = as.double(valores[5])

vdi2 = as.double(valores[6])

```

Vemos para o gráfico de Medida h, o ponto que se destaca é o de indice `r indh`, com valor de `r vh`. Já no de Distânca de Cook, temos dois pontos em destaque: um é o do mesmo indice,com valor `r vdi2`, coomparações entre os valores das duas medidas não consistentes e portanto inválidas, outro ponto é o de indice `r inddi1`, com valor `r vdi1`.

Logo, como identificamos esses pontos, vamos montar um modelo reduzido, como feito acima mas excluindo primeiramente as observações de indice 40 pois nos dois caso é o ponto mais elevado, possívelmente o que mais influência no modelo. caso ocorra uma melhora de ajuste, faremos para o outro identificado pela Distância de Cook.

Segue abaixo o ajuste do modelo sem a observação 40

```{r}

fit_otimo_adj1 <- lm(expvida ~ crime + estud + ndias + dens, data = dados[-4,])


res_fit_otimo_adj1 = summary(fit_otimo_adj1)
coeff_fit_otimo_adj1 = res_fit_otimo_adj1$coefficients
coeff_fit_otimo_adj1 = data.frame(round(as.double(coeff_fit_otimo_adj1[,1]),4),round(as.double(coeff_fit_otimo_adj1[,2]),4),round(as.double(coeff_fit_otimo_adj1[,3]),4),ifelse(as.double(coeff_fit_otimo_adj1[,4]) < 0.0001, "<0.0001", round(as.double(coeff_fit_otimo_adj1[,4]),4)))

names(coeff_fit_otimo_adj1)=c("Estimativa","EP","Valor T","Valor p")

# Estatísticas para comparação de modelos
medidas_fit_otimo_adj1 = data.frame(rbind(AIC(fit_otimo_adj1),BIC(fit_otimo_adj1),logLik(fit_otimo_adj1)))
colnames(medidas_fit_otimo_adj1)=c("Modelo 3")
rownames(medidas_fit_otimo_adj1)=c("AIC","BIC","Log-Verossimilhança")



mm_adj1 = as.matrix(model.matrix(fit_otimo_adj1))
```

```{r residuos modelo otimo ajustado 1,echo = FALSE,warning=FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#grpaficos para análise de resíduos
diag2norm(fit_otimo_adj1)
```

```{r envelope modelo otimo ajustado 1,echo = FALSE,warning=FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#gráfico de envelopes
envelnorm(fit_otimo_adj1)
```

```{r}

fit_otimo_adj2 <- lm(expvida ~ crime + estud + ndias + dens, data = dados[-c(11,40),])

res_fit_otimo_adj2 = summary(fit_otimo_adj2)
coeff_fit_otimo_adj2 = res_fit_otimo_adj2$coefficients
coeff_fit_otimo_adj2 = data.frame(round(as.double(coeff_fit_otimo_adj2[,1]),4),round(as.double(coeff_fit_otimo_adj2[,2]),4),round(as.double(coeff_fit_otimo_adj2[,3]),4),ifelse(as.double(coeff_fit_otimo_adj2[,4]) < 0.0001, "<0.0001", round(as.double(coeff_fit_otimo_adj2[,4]),4)))

names(coeff_fit_otimo_adj1)=c("Estimativa","EP","Valor T","Valor p")

# Estatísticas para comparação de modelos
medidas_fit_otimo_adj2 = data.frame(rbind(AIC(fit_otimo_adj2),BIC(fit_otimo_adj2),logLik(fit_otimo_adj2)))
colnames(medidas_fit_otimo_adj2)=c("Modelo 4")
rownames(medidas_fit_otimo_adj2)=c("AIC","BIC","Log-Verossimilhança")



mm_adj1 = as.matrix(model.matrix(fit_otimo_adj1))
```

```{r residuos modelo otimo ajustado 2,echo = FALSE,warning=FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#grpaficos para análise de resíduos
diag2norm(fit_otimo_adj2)
```

```{r envelope modelo otimo ajustado 2,echo = FALSE,warning=FALSE}
#echo = FALSE não permite que o chunk apareça no pdf

#gráfico de envelopes
envelnorm(fit_otimo_adj2)
```




```{r}

medidas_comp_model = data.frame(medidas_fit_max,medidas_fit_otimo,medidas_fit_otimo_adj1,medidas_fit_otimo_adj2)



```



#Conclusões